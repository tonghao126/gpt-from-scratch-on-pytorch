{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Video Link](https://www.youtube.com/watch?v=kCc8FmEb1nY&t=477s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt -O ../data/raw/input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "# autorefresh\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/raw/input.txt', 'r') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "def test_func(abc, **kwargs):\n",
    "    print(abc)\n",
    "\n",
    "test_func(**{'abc': 1, 'def': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_mapping = {c: i for i, c in enumerate(chars)}\n",
    "decode_mapping = {i: c for i, c in enumerate(chars)}\n",
    "encoder = lambda x: [encode_mapping[s] for s in x]\n",
    "decoder = lambda x: ''.join([decode_mapping[s] for s in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "device='mps'\n",
    "token_embeddings = nn.Embedding(vocab_size, 10, device=device)(x)\n",
    "pos_embeddings = nn.Embedding(8, 10, device=device)(torch.tensor([1, 2, 3, 4, 5, 6, 7, 0], device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 10])"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embeddings.shape\n",
    "pos_embeddings.shape\n",
    "(token_embeddings+pos_embeddings).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# Not sure why but for the Bigram mps is significantly slower than cpu\n",
    "device='mps'\n",
    "data = torch.tensor(encoder(text), dtype=torch.long, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "n = int(0.9*len(data))\n",
    "train = data[:n]\n",
    "test = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: torch.Size([4, 8]) :\n",
      " tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]], device='mps:0')\n",
      "Y: torch.Size([4, 8]) :\n",
      " tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
      "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
      "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
      "        [17, 27, 10,  0, 21,  1, 54, 39]], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "block_size = 8\n",
    "batch_size = 4\n",
    "\n",
    "def get_batch(data, batch_size):\n",
    "    data_slice = torch.randint(0, len(data)-block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in data_slice])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in data_slice])\n",
    "    return  x, y\n",
    "\n",
    "x, y = get_batch(train, batch_size)\n",
    "print('X:',x.shape,':\\n', x)\n",
    "print('Y:',y.shape,':\\n', y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplist Bigram model which only uses two words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.7311, device='mps:0', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torch.nn import functional as F\n",
    "# Bigram is just pairwise model\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size) -> None:\n",
    "        super().__init__()\n",
    "        # Not sure why he uses vocab_size as the embedding dim, maybe just convenient? It's usually multiple of 2\n",
    "        self.embedding = nn.Embedding(vocab_size, vocab_size, device=device)\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        logits = self.embedding(x) # (Batch, Time, Channels) Time=word sequence, Channels=Embedding\n",
    "        # This logic seems quite confusing, is there anyway to optimize this?\n",
    "        if y is None:\n",
    "            loss=None\n",
    "        else:\n",
    "            B,T,C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            y = y.view(-1)\n",
    "            # Lesson, check documentation and see if order is as intended\n",
    "            loss = F.cross_entropy(logits, y)\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, x, max_tokens=100):\n",
    "        # output depends on input's shape, so if input shape is (1, T), output will be (1, T, C)\n",
    "        for i in range(max_tokens):\n",
    "            logits, loss = self(x)\n",
    "            # print(f'logits.shape is {logits.shape}')\n",
    "            # Due to weird forward logic, when generating, logits is not reshaped\n",
    "            generated = logits[:,-1,:] # B,C\n",
    "            probs = nn.Softmax(dim=-1)(generated)\n",
    "            next_tokens = torch.multinomial(probs, 1)\n",
    "            print(next_tokens.shape)\n",
    "            x = torch.cat([x, next_tokens], dim=1)\n",
    "        return x\n",
    "    \n",
    "model = BigramLanguageModel(vocab_size).to(device)\n",
    "out, loss = model(x, y)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 8])"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 8, 2])"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([x, x], dim=2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 16])"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([x, x], dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_list = [x,x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cat([x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 2.4873929023742676\n",
      "Epoch 1, Loss: 2.4554905891418457\n",
      "Epoch 2, Loss: 2.4300172328948975\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "n_epochs= 3\n",
    "batch_size = 32\n",
    "n_steps = 1000\n",
    "\n",
    "# TODO: understand better here, does the order matter?\n",
    "for epoch in range(n_epochs):\n",
    "    for _ in range(n_steps):\n",
    "        x, y = get_batch(train, batch_size)\n",
    "        _, loss = model(x, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch {epoch}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1]), tensor([ 2,  3,  4,  5,  6,  7,  8,  9, 10]))"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.split(torch.tensor([1,2,3,4,5,6,7,8,9,10]), [1,9], dim=0).cat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n",
      "torch.Size([1, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0, 46,  6, 15, 21, 24, 25, 58, 62,  5, 10, 19, 19, 61, 22, 16, 50, 10,\n",
       "         50, 63, 62, 26, 25, 51,  2, 48,  6, 45, 14, 51, 12, 14, 51, 41, 45, 45,\n",
       "         13, 36, 18, 41, 32, 37, 18,  4, 30,  2, 58, 55, 39, 41, 25, 59, 38, 28,\n",
       "          7, 19, 50, 47, 49,  4, 21,  6,  7,  5, 29, 10, 19,  2, 34,  4, 28, 24,\n",
       "         62, 39, 47, 61, 54, 58, 33, 55, 33, 59, 15, 34, 54, 24, 43, 56, 56, 63,\n",
       "         21, 60, 61,  8, 47, 32,  0, 33,  9,  0,  0]], device='mps:0')"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate(torch.zeros(1,1, dtype=torch.long, device=device), max_tokens=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'logits' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[309], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(decoder(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()))\n",
      "Cell \u001b[0;32mIn[306], line 23\u001b[0m, in \u001b[0;36mBigramLanguageModel.generate\u001b[0;34m(self, x, max_tokens)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m):\n\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogits.shape is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mlogits\u001b[49m\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_tokens):\n\u001b[1;32m     25\u001b[0m         logits, loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(x)\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'logits' referenced before assignment"
     ]
    }
   ],
   "source": [
    "print(decoder(model.generate(torch.zeros(1,1, dtype=torch.long, device=device), max_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "B,T,C = 4, 8, 2\n",
    "x = torch.randn(B,T,C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xbow = torch.zeros(B,T,C)\n",
    "# for b in range(B):\n",
    "#     for t in range(T):\n",
    "#         x_prev = x[b, :t+1] # t,C\n",
    "#         xbow[b,t] = x_prev.mean(axis=0) # bag of words\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "tri = torch.tril(torch.ones(T,T))\n",
    "# Don't forget normalization \n",
    "tri_norm = tri / tri.sum(axis=1, keepdim=True) # notice the keepdim\n",
    "xbow = tri_norm @ xbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 3\n",
    "tri = torch.tril(torch.ones(T,T))\n",
    "wei = torch.zeros(T,T)\n",
    "masked = wei.masked_fill(tri==0, float('-inf'))\n",
    "tri_norm = torch.softmax(masked, dim=-1)\n",
    "xbow = tri_norm @ xbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
       "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tri_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.7293,  1.7776,  0.4130,  0.9263, -2.6684, -0.0425,  3.4025,\n",
       "          -1.1335],\n",
       "         [-1.1056, -2.0497,  0.5517, -3.0066,  1.7959,  1.2291,  0.6362,\n",
       "           1.8547],\n",
       "         [-0.2204,  0.9991, -0.4337, -0.4233,  1.1247, -0.4147, -1.4429,\n",
       "           0.3976],\n",
       "         [ 0.9109, -1.5431, -2.4327,  0.3213, -0.3392, -0.1686, -0.0611,\n",
       "          -0.0707],\n",
       "         [-2.1553, -2.0961,  1.0414, -0.2077,  1.1906,  0.2539, -1.1959,\n",
       "           0.7533],\n",
       "         [ 2.6176,  1.4151, -1.1325, -0.8985,  1.3273, -1.0891, -1.8364,\n",
       "          -0.2618],\n",
       "         [ 1.4695,  0.8811, -0.9591, -1.6081, -0.8878,  1.7417, -0.2726,\n",
       "          -1.3540],\n",
       "         [-0.6524, -0.4305, -0.8854, -1.2430,  0.5488,  0.3144,  0.7821,\n",
       "          -0.7590]],\n",
       "\n",
       "        [[ 1.3132, -1.7015, -0.4501,  0.8765,  0.8277,  0.1446, -1.0251,\n",
       "           0.4049],\n",
       "         [ 0.2882, -0.9414,  1.0976, -0.0939,  2.0157,  2.1101,  2.6527,\n",
       "          -2.2760],\n",
       "         [ 1.4726, -0.7085, -1.7851,  0.6409, -1.5864,  0.9529, -5.8391,\n",
       "           5.9636],\n",
       "         [ 1.5922, -1.0093, -0.6359,  0.4326,  0.0209,  0.0891, -1.6484,\n",
       "           0.5649],\n",
       "         [-0.7718,  1.4327, -0.0350, -0.9078, -0.4163, -0.9785,  1.1145,\n",
       "          -0.6694],\n",
       "         [-2.9423,  1.4200,  0.9878, -1.3638, -1.5585,  0.9969,  1.2085,\n",
       "          -0.0095],\n",
       "         [-2.2216,  1.0207,  0.3359, -0.3743, -2.2437, -0.2594,  0.8971,\n",
       "          -0.9883],\n",
       "         [-0.9370,  1.9897,  2.1801,  0.8555, -0.9425, -0.2342,  1.4538,\n",
       "          -2.2354]],\n",
       "\n",
       "        [[ 0.4273,  2.7269, -0.6383,  2.9272,  2.3105, -4.2828,  0.9408,\n",
       "           1.5767],\n",
       "         [-2.5430,  1.9005,  0.9224, -1.6735,  0.4460,  1.9162, -1.5432,\n",
       "           1.2144],\n",
       "         [ 0.3107,  0.9814,  2.0588,  0.7405,  0.7550, -0.1431,  0.5332,\n",
       "          -0.1231],\n",
       "         [-0.2603,  2.5293,  0.5321,  0.9218,  4.2014,  0.0810,  0.6266,\n",
       "           1.6368],\n",
       "         [ 1.9674,  1.7543,  1.3084, -0.7466,  0.9414, -0.3506, -1.7375,\n",
       "           3.0528],\n",
       "         [-3.2665, -3.0973, -1.3381, -0.2489, -1.5324,  3.3825,  0.9137,\n",
       "          -2.8615],\n",
       "         [ 0.3644,  0.5834,  1.3752,  0.8324,  3.5545, -3.8274,  0.1038,\n",
       "          -0.4960],\n",
       "         [-1.2104, -1.7133, -3.3214,  2.0644, -0.9389,  3.3128,  2.4311,\n",
       "          -2.9418]],\n",
       "\n",
       "        [[-1.9127,  0.7265, -1.0013,  1.9826, -0.9908,  1.0366, -0.7808,\n",
       "          -0.6129],\n",
       "         [ 0.5003,  0.1831,  0.6639, -0.2940,  1.5854,  0.6053, -0.1571,\n",
       "          -0.3283],\n",
       "         [ 0.7716,  0.0204,  0.9385,  0.1553, -0.1929, -0.3480,  0.9140,\n",
       "           1.1866],\n",
       "         [-0.8428, -0.9679,  1.8284, -2.3023, -0.5444,  1.1842, -1.9642,\n",
       "           2.5084],\n",
       "         [ 0.8295, -1.5908, -0.0242,  1.3048, -0.2479, -0.5323,  0.6147,\n",
       "          -2.6516],\n",
       "         [ 0.1346,  0.4681,  0.8711, -2.9140,  1.7397,  1.0275, -1.1722,\n",
       "           1.1246],\n",
       "         [ 0.1867,  0.7822, -2.4185,  0.0970, -0.2774,  1.1134, -1.8606,\n",
       "           1.1002],\n",
       "         [-1.4625,  0.5159,  0.0159,  0.7592, -1.0136, -0.4307,  2.4307,\n",
       "          -0.4966]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from multiprocessing import Value\n",
    "\n",
    "\n",
    "B = 4\n",
    "T = 8\n",
    "C = 32\n",
    "# Self attention mechanism\n",
    "head_size = 16\n",
    "\n",
    "\n",
    "x = torch.randn(B,T,C)\n",
    "# ask\n",
    "query = nn.Linear(C, head_size, bias=False) # B,T,C\n",
    "# look more into it\n",
    "key = nn.Linear(C, head_size, bias=False) # B,T,C\n",
    "# intuition: simply linearly transformed raw x\n",
    "Value = nn.Linear(C, head_size, bias=False) # B,T,C\n",
    "\n",
    "k = key(x) # B,T,H\n",
    "q = query(x) # B,T,H \n",
    "\n",
    "q@k.transpose(-2, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of BigramLanguageModel(\n",
       "  (embedding): Embedding(65, 65)\n",
       ")>"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "learning_rate = 1e-3\n",
    "n_epochs= 10\n",
    "n_steps = 1000\n",
    "batch_size = 32\n",
    "block_size = 8\n",
    "device='cpu'\n",
    "n_embed = 32\n",
    "head_size = 16\n",
    "n_attentions = 8\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, n_embed, head_size) -> None:\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embed, head_size, device=device)\n",
    "        self.query = nn.Linear(n_embed, head_size, device=device)\n",
    "        self.value = nn.Linear(n_embed, head_size, device=device)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        k = self.key(x)\n",
    "        q = self.query(x)\n",
    "        v = self.value(x)\n",
    "        # Weight is the key to self attention mechanism, essentially which previous key is more relevant to current k\n",
    "        weight = q@k.transpose(-2,-1)* head_size**-0.5 # B,T,H @ B,H,T -> B,T,T\n",
    "\n",
    "        # apply triangle mask, note the order of things. I.e. when to apply mask, softmax and multply by v at the end\n",
    "        # TODO: the implementation here is different from Andrej's, would this screw things up downstream?\n",
    "        tri = torch.tril(torch.ones(block_size,block_size, device=device))\n",
    "        weight = weight.masked_fill(tri==0, float('-inf'))\n",
    "        weight = torch.softmax(weight, dim=-1)\n",
    "        weight = weight@v # B,T,T @ B,T,H -> B,T,H\n",
    "        return weight\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, vocab_size) -> None:\n",
    "        super().__init__()\n",
    "        self.token_embedding = nn.Embedding(vocab_size, n_embed, device=device)\n",
    "        self.pos_embedding = nn.Embedding(block_size, n_embed, device=device)\n",
    "        self.self_attention = SelfAttention(n_embed, head_size)\n",
    "        self.fc = nn.Linear(head_size*n_attentions, vocab_size, device=device)\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        char_embedding_layer = self.token_embedding(x) # (Batch, Time, Channels) Time=word sequence, Channels=embed_size\n",
    "        pos_embedding_layer = self.pos_embedding(torch.arange(block_size, device=device)) # (T, C)\n",
    "        x = char_embedding_layer + pos_embedding_layer\n",
    "        # TODO: separate multi headed attention to a separate class, and see why I'm not reaching 3.2 in error\n",
    "        weight = torch.cat([self.self_attention(x) for i in range(n_attentions)],dim=-1) # B,T,H*N_attentions -> B,T,H*N_attentions\n",
    "        logits = self.fc(weight) # B,T,T @ B,T,H -> B,T,H\n",
    "        # TODO: normalization\n",
    "        \n",
    "        # When generating, y is None\n",
    "        if y is None:\n",
    "            loss=None\n",
    "        else:\n",
    "            B,T,C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            y = y.view(-1)\n",
    "            # Lesson, check documentation and see if order is as intended\n",
    "            loss = F.cross_entropy(logits, y)\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, x, max_tokens=100):\n",
    "        for i in range(max_tokens):\n",
    "            idx_block = x[:,-block_size:]\n",
    "            logits, loss = self(idx_block)\n",
    "            # Due to weird forward logic, when generating, logits is not reshaped\n",
    "            generated = logits[:,-1,:] # B,C\n",
    "            probs = nn.Softmax(dim=-1)(generated)\n",
    "            next_tokens = torch.multinomial(probs, 1)\n",
    "            x = torch.cat([x, next_tokens], dim=1)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of Transformer(\n",
       "  (token_embedding): Embedding(65, 32)\n",
       "  (pos_embedding): Embedding(8, 32)\n",
       "  (self_attention): SelfAttention(\n",
       "    (key): Linear(in_features=32, out_features=16, bias=True)\n",
       "    (query): Linear(in_features=32, out_features=16, bias=True)\n",
       "    (value): Linear(in_features=32, out_features=16, bias=True)\n",
       "  )\n",
       "  (fc): Linear(in_features=128, out_features=65, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass(kw_only=True)\n",
    "class Config:\n",
    "    learning_rate:float = 5e-4\n",
    "    n_epochs:int = 5\n",
    "    n_steps:int = 1000\n",
    "    batch_size:float = 64\n",
    "    block_size = 64\n",
    "    device='mps'\n",
    "    n_embed = 384\n",
    "    n_heads = 8\n",
    "    head_size = n_embed//n_heads\n",
    "    n_blocks = 3\n",
    "    # Accoridng to paper, output of each sub-layer, before it is added to the\n",
    "    # sub-layer input and normalized. In addition, we apply dropout to the sums of the embeddings and the positional encodings\n",
    "    dropout = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Config(learning_rate=0.0005, n_epochs=5, n_steps=1000, batch_size=32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = Config(batch_size=32)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': '5e-4',\n",
       " 'n_epochs': 5,\n",
       " 'n_steps': 1000,\n",
       " 'batch_size': 64,\n",
       " 'block_size': 64,\n",
       " 'device': 'mps',\n",
       " 'n_embed': 384,\n",
       " 'n_heads': 8,\n",
       " 'n_blocks': 3,\n",
       " 'dropout': 0.1}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml\n",
    "test = yaml.load(open('../config/default_config.yaml', 'r'), Loader=yaml.FullLoader)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.0005,\n",
       " 'n_epochs': 5,\n",
       " 'n_steps': 1000,\n",
       " 'batch_size': 64,\n",
       " 'block_size': 64,\n",
       " 'device': 'mps',\n",
       " 'n_embed': 384,\n",
       " 'n_heads': 8,\n",
       " 'n_blocks': 3,\n",
       " 'dropout': 0.1,\n",
       " 'head_size': 48}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.utils.config import Config\n",
    "config = Config()\n",
    "config.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "else\n"
     ]
    }
   ],
   "source": [
    "from math import e\n",
    "\n",
    "\n",
    "def test_match(match):\n",
    "    match match:\n",
    "        case 1:\n",
    "            print('1')\n",
    "        case 2:\n",
    "            print('2')\n",
    "        case whatever:\n",
    "            print('else')\n",
    "\n",
    "test_match(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for |: 'str' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ma\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m|\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for |: 'str' and 'str'"
     ]
    }
   ],
   "source": [
    "'a' | 'b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.0005, 'n_epochs': 5, 'n_steps': 1000, 'batch_size': 32}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Person(name='John Doe', age=30, city='New York')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sympy import per\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Person:\n",
    "    name: str = 'John Doe'\n",
    "    age: int = 30\n",
    "    city: str = 'New York'\n",
    "\n",
    "person = Person()\n",
    "person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/htong/Library/Caches/pypoetry/virtualenvs/gpt-from-scratch-on-pytorch-6GLuoSPu-py3.10/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dropout\n\u001b[0;32m----> 4\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[43mConfig\u001b[49m()\n\u001b[1;32m      5\u001b[0m config\u001b[38;5;241m.\u001b[39mdropout\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Config' is not defined"
     ]
    }
   ],
   "source": [
    "from torch import dropout\n",
    "\n",
    "\n",
    "config = Config()\n",
    "config.dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[43mConfig\u001b[49m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Config' is not defined"
     ]
    }
   ],
   "source": [
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Config()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt-from-scratch-on-pytorch-6GLuoSPu-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
